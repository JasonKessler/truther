{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from glob import glob\n",
    "import os, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.en.English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_pattern_to_matcher(veridicality_element_class, tokens):\n",
    "    matcher.add_pattern(veridicality_element_class, \n",
    "                        [{spacy.matcher.attrs.LOWER: token} for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from kanren import Relation, facts\n",
    "from kanren import run, eq, membero, var, conde, vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VeriticalityElements(object):\n",
    "    def __init__(self):\n",
    "        unsorted_patterns = []\n",
    "        for file_name in self._list_veridicality_element_files():\n",
    "            for line in open(file_name).readlines():\n",
    "                ve_class_name = os.path.basename(file_name)\n",
    "                ve_tokens = line.strip().lower().split()\n",
    "                unsorted_patterns.append([-len(ve_tokens), ve_tokens, ve_class_name])\n",
    "        self._patterns = [(tokens, ve_class) \n",
    "                          for _, tokens, ve_class \n",
    "                          in sorted(unsorted_patterns)]\n",
    "    def _list_veridicality_element_files(self):\n",
    "        return glob('lexicon/*')\n",
    "    def get_patterns(self):\n",
    "        return self._patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Sentence(object):\n",
    "    def __init__(self, doc, toks, follows_facts, headof_facts, label_facts):\n",
    "        self.doc = doc\n",
    "        self.toks = toks\n",
    "        self.follows_facts = follows_facts\n",
    "        self.headof_facts = headof_facts\n",
    "        self.label_facts = label_facts\n",
    "        self.tok_index = {tok:i for i,tok in self.toks}\n",
    "    \n",
    "    def print_labeled(self):\n",
    "        for i,tok in self.toks:\n",
    "            x=var()\n",
    "            print(i, tok, [label for label_i,label in self.label_facts if i == label_i])\n",
    "\n",
    "    def print_orig(self):\n",
    "        print(doc)\n",
    "    \n",
    "    def search_and_merge(self, search, label):\n",
    "        try:\n",
    "            start_idx = self.tok_index[search[0]]\n",
    "        except KeyError:\n",
    "            return self\n",
    "        if start_idx + len(search) > len(self.toks):\n",
    "            return self\n",
    "        toks_to_merge = [i for i,tok in self.toks[start_idx:start_idx+len(search)]]\n",
    "        return self._merge_and_label_elements(toks_to_merge, label)\n",
    "            \n",
    "    \n",
    "    def search_and_merge_old(self, search, label):\n",
    "        search_vars = {tok: var() for tok in search}\n",
    "        clauses = [self.nameof(search_vars[tok], tok) for tok in search]\n",
    "        if len(search) > 1:\n",
    "            clauses += [self.follows(search_vars[left], search_vars[right]) \n",
    "               for left,right in zip(search[:-1], search[1:])]\n",
    "        matches = run(1, search_vars[search[0]], *clauses)\n",
    "        if len(matches) > 0:\n",
    "            match = matches[0]\n",
    "            elements_to_merge = [match]\n",
    "            cur_element = match\n",
    "            for i in range(len(search) - 1):\n",
    "                x = var()\n",
    "                cur_element = run(1, x, follows(cur_element, x))[0]\n",
    "                elements_to_merge.append(cur_element)\n",
    "            return self._merge_and_label_elements(elements_to_merge, label)\n",
    "        else:\n",
    "            return self\n",
    "        \n",
    "    def _merge_and_label_elements(self, elements_to_merge, label):\n",
    "        self.label_facts.append((elements_to_merge[0], label))\n",
    "        #facts(self.labels, (elements_to_merge[0], label))\n",
    "        if len(elements_to_merge) == 1:\n",
    "            return self\n",
    "        else:\n",
    "            new_toks = []\n",
    "            new_follows_facts = []\n",
    "            new_headof_facts = []\n",
    "            last_tok = None\n",
    "            headof_dict = {}\n",
    "            for tok_i, head_i in self.headof_facts:\n",
    "                headof_dict.setdefault(tok_i, []).append(head_i)\n",
    "            \n",
    "            for i, tok in self.toks:\n",
    "                cur_tok = None\n",
    "                if i not in elements_to_merge:\n",
    "                    cur_tok = (i, tok)\n",
    "                    new_toks.append(cur_tok)\n",
    "                    for head_i, rel in headof_dict[i]:\n",
    "                        if head_i in elements_to_merge:\n",
    "                            new_headof_facts.append((i, (elements_to_merge[0], rel)))\n",
    "                        else: \n",
    "                            new_headof_facts.append((i, (head_i, rel)))\n",
    "                elif i == elements_to_merge[0]:\n",
    "                    new_string = ' '.join([tok for i, tok in self.toks \n",
    "                                           if i in elements_to_merge])\n",
    "                    new_i = elements_to_merge[0];\n",
    "                    cur_tok = (new_i, new_string)\n",
    "                    new_toks.append(cur_tok)\n",
    "                    for el_to_merge_i in elements_to_merge:\n",
    "                        for head_i, rel in headof_dict[el_to_merge_i]:\n",
    "                            if head_i not in elements_to_merge:\n",
    "                                new_headof_facts.append((new_i, (head_i, rel)))\n",
    "                if cur_tok is not None and last_tok is not None:\n",
    "                    new_follows_facts.append((last_tok[0], cur_tok[0]))\n",
    "                if cur_tok is not None:\n",
    "                    last_tok = cur_tok\n",
    "            return Sentence(doc, new_toks, new_follows_facts, new_headof_facts, copy.copy(self.label_facts))\n",
    "        \n",
    "def make_sentence_from_doc(doc):\n",
    "    toks = [(tok.i, tok.lower_) for tok in doc]\n",
    "    tokidx = [i for i,tok in toks]\n",
    "    follows_facts = list(zip(tokidx, (tokidx[1:] + [None])))\n",
    "    headof_facts = [(tok.i, (-1 if tok.head == tok else tok.head.i, tok.dep_)) for tok in doc]\n",
    "    return Sentence(doc, toks, follows_facts, headof_facts, [])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-38-ff81518adf44>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-ff81518adf44>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# start of vertidicality transformation code\n",
    "# !!! to do\n",
    "class SentenceFinder(object):\n",
    "    def find(self, query):\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp('If however you think abortion is murder, then this story will make you sick.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if ['conditionals']\n",
      "1 however ['causals']\n",
      "2 you []\n",
      "3 think ['positive_verbs']\n",
      "4 abortion is murder ['proposition']\n",
      "7 , []\n",
      "8 then []\n",
      "9 this []\n",
      "10 story []\n",
      "11 will []\n",
      "12 make ['positive_nouns']\n",
      "13 you []\n",
      "14 sick . ['counter_factive_verbs']\n"
     ]
    }
   ],
   "source": [
    "sent = make_sentence_from_doc(doc)\n",
    "\n",
    "sent = sent.search_and_merge('abortion is murder'.split(), 'proposition')\n",
    "veridicality_elements = VeriticalityElements()\n",
    "for pattern, label in veridicality_elements.get_patterns():\n",
    "    sent = sent.search_and_merge(pattern, label)\n",
    "sent.print_labeled()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "goal() missing 1 required positional argument: 'substitution'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-317-322cd7e3ee4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'believe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: goal() missing 1 required positional argument: 'substitution'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should stop your make believe that abortion is murder.\n",
      "[~make, ~believe]\n",
      "[<function Relation.__call__.<locals>.goal at 0x17643f7b8>, <function Relation.__call__.<locals>.goal at 0x1762ee730>, <function Relation.__call__.<locals>.goal at 0x1762ee840>]\n",
      "['make', 'believe'] ()\n",
      "You should stop your make believe that abortion is murder.\n",
      "[~belie]\n",
      "[<function Relation.__call__.<locals>.goal at 0x17643f7b8>]\n",
      "['belie'] ()\n",
      "You should stop your make believe that abortion is murder.\n",
      "[~believe]\n",
      "[<function Relation.__call__.<locals>.goal at 0x17643f7b8>]\n",
      "['believe'] ()\n",
      "You should stop your make believe that abortion is murder.\n",
      "[~er]\n",
      "[<function Relation.__call__.<locals>.goal at 0x17643f7b8>]\n",
      "['er'] ()\n",
      "You should stop your make believe that abortion is murder.\n",
      "[~lie]\n",
      "[<function Relation.__call__.<locals>.goal at 0x17643f7b8>]\n",
      "['lie'] ()\n"
     ]
    }
   ],
   "source": [
    "#sent = 'If however you think abortion is murder, then this story will make you sick.'\n",
    "raw = 'You should stop your make believe that abortion is murder.'\n",
    "sent = Sentence(nlp(raw))\n",
    "ves = VeriticalityElements()\n",
    "sent.match(ves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
